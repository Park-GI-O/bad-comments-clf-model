{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffcf7c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd73a46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hate : 0\n",
    "# none : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4712f404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>lable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이종석 한효주 나오는 드라마 이후로 드라마 안봤다. 2년전인가?? 좀 신선했었지. ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>씨바알..노무노무 술프노... 오늘 저녁은 꽂등심이다ㅠㅜ</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>짱깨 꺼라ㅡ패쓰</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그들의 사생활 ~ 고인이된 설리를 위해서라도 모두 조용하길 지금 누굴 탓한다고 무슨...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>아무리 법이 뭣같아도 무슨 자격으로 개인의 신상정보를 불특정 다수에게 공개하는지 도...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>이거 보다 더한 막장의 드라마도 넋놓고 보면서 무슨?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>머...제네시스..올라프에디션?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>항상 여자로 ㅡ ㅡ 저지랄 들이야 남자들 벗겨봐라</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>첫번째 이유가 ㄹㅇ 맞지특히나 뉴스나 기사 몇줄읽은 학생들끼리 대화해도 서로 존나 ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Lg폰 누가쓰냐 gps도 못잡는폰 쓰래기 통에나 버려라</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  lable\n",
       "0     이종석 한효주 나오는 드라마 이후로 드라마 안봤다. 2년전인가?? 좀 신선했었지. ...    0.0\n",
       "1                       씨바알..노무노무 술프노... 오늘 저녁은 꽂등심이다ㅠㅜ    0.0\n",
       "2                                              짱깨 꺼라ㅡ패쓰    0.0\n",
       "3     그들의 사생활 ~ 고인이된 설리를 위해서라도 모두 조용하길 지금 누굴 탓한다고 무슨...    1.0\n",
       "4     아무리 법이 뭣같아도 무슨 자격으로 개인의 신상정보를 불특정 다수에게 공개하는지 도...    1.0\n",
       "...                                                 ...    ...\n",
       "9995                      이거 보다 더한 막장의 드라마도 넋놓고 보면서 무슨?    1.0\n",
       "9996                                  머...제네시스..올라프에디션?    1.0\n",
       "9997                        항상 여자로 ㅡ ㅡ 저지랄 들이야 남자들 벗겨봐라    0.0\n",
       "9998  첫번째 이유가 ㄹㅇ 맞지특히나 뉴스나 기사 몇줄읽은 학생들끼리 대화해도 서로 존나 ...    0.0\n",
       "9999                     Lg폰 누가쓰냐 gps도 못잡는폰 쓰래기 통에나 버려라    0.0\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv('C:/Users/Haejin Lee/OneDrive/바탕 화면/세미 프로젝트/data/data1.csv', sep='\\t')\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d949e414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   content  10000 non-null  object \n",
      " 1   lable    9975 non-null   float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 156.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e146546",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data1.rename(columns={'lable':'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd8cd5b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>응애 응애 엄마 저 맘에 안들죠? ........아들 ?? \" 너 내가 우스워 보이...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>토니스타크 평소 \"아이엠그루트\"라는 유행어를 부러워했다는게 학계의 정설</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>\"13일 현대차에 따르면 올 들어 국내 소비자들의 수입차 구매의향률이 3년 만에 하...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2920</th>\n",
       "      <td>에이프릴이 한마디 합니다 \"예쁜게 죄\" 구하라님 \"무기징역\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3720</th>\n",
       "      <td>답글 글씨체를 봐라 저게 애새끼가 쓴거냐?\"빨갱이새끼가 쓴거지 ㅁㅈㅎㅉㅉ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3807</th>\n",
       "      <td>알겠다이기ㅋㅋ 딱 채찍쳐맞는거 좋아하는 한국식 마인드네. 노예마인드. 조금만 성공한...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908</th>\n",
       "      <td>이래서 스스로 걸리거든 \"죄인들이\"~ㅎㅎㅎ 재미보고 털리고 그치~~~?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4241</th>\n",
       "      <td>아버지는 내재된 악마들을 다룰 정신적 힘을 가지고 있지 않았다.\" 이 말한마디가 사...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>댓글 중 \"선동 당해서 촞불든 개돼지 홍어들도 단죄를 받아야 할 공범자들이다\"에100ㅂ!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>스파이 제안받고 살해 안당하는 법1. 처음에 스파이 제안을 받았을때 \"중국을 위해서...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5521</th>\n",
       "      <td>\"국방부 \"까지 ㅡㄱ ㅐ 엿같은 ㅈ ㅣ랄주댕이...좌빨에서 ㅡ인민군대로 ㅡ가려는건가?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5866</th>\n",
       "      <td>쌩뚱맞게 60대최반엌 치매라니 그것도 곱게 사는 사모님이- -\" 알콜중독도 아니고 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6477</th>\n",
       "      <td>페미메퇘지쿵쾅년인 메갈페미들은 니들이 좋아하는 싫어요 ㄱㄱ제발부탁해~~\"일반 여성\"...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6538</th>\n",
       "      <td>아니 ㅆㅂ 그런 \"카더라\"가 넘쳐난다고 그거에 대해서 혹시 댓글게이는 뭔가 아는거 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6771</th>\n",
       "      <td>저 때 투니버스에서 코요태 짧게 인터뷰 했었는데 김종민이 \"노래는 뭐 신지가 다 하...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6932</th>\n",
       "      <td>개 족 가튼 국방부의 \"휴기연장콜센터\"발족을 축하한다 ㅆ ㅂ..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7199</th>\n",
       "      <td>민족적 자존심과 애국심을 갖고 국산품 이용합시다 . . . \"겸손\"한 마음으로 재산...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7252</th>\n",
       "      <td>아나운서는 목표가 아니었지ㅋㅋ재벌하고 결혼하자마자 바로 은퇴하네ㅋㅋ무슨 인터뷰한 거...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>결국 준영과 다솜은 바람을 피게되고 무인도로 떠난다에 한표 ㅋㅋㅋ 자연인이 되어 \"...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7480</th>\n",
       "      <td>지금 연락하는 여자랑 폰섹 엄청 많이했는데만나서 호텔 들어가서침대에 서로 마주보고 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499</th>\n",
       "      <td>몽골한테 \"최근에\" 250년간 지배당하고 집단강간을 당했는데 동양피가 하나도 안섞였...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7887</th>\n",
       "      <td>뭐 선천적으로 여성스럽거나 여자역할을 하고 싶어하는 동성애자들 그럴 수 있다고는 생...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9666</th>\n",
       "      <td>ㄹㅇ 시발 그냥 \"다른 진로 생각해 보세요\"라고만 했어도 욕 안처 먹었지.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9698</th>\n",
       "      <td>간만에 이단어가 떠오르는군 \"이뭐병\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9875</th>\n",
       "      <td>노라조 \"형\"이란 노래로 힘들 때 위로를 받곤 했습니다. 앞으로도 노라조라는 이름으...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content label\n",
       "1602  응애 응애 엄마 저 맘에 안들죠? ........아들 ?? \" 너 내가 우스워 보이...     0\n",
       "1654            토니스타크 평소 \"아이엠그루트\"라는 유행어를 부러워했다는게 학계의 정설     1\n",
       "1992  \"13일 현대차에 따르면 올 들어 국내 소비자들의 수입차 구매의향률이 3년 만에 하...     1\n",
       "2920                  에이프릴이 한마디 합니다 \"예쁜게 죄\" 구하라님 \"무기징역\"     1\n",
       "3720           답글 글씨체를 봐라 저게 애새끼가 쓴거냐?\"빨갱이새끼가 쓴거지 ㅁㅈㅎㅉㅉ     0\n",
       "3807  알겠다이기ㅋㅋ 딱 채찍쳐맞는거 좋아하는 한국식 마인드네. 노예마인드. 조금만 성공한...     0\n",
       "3908            이래서 스스로 걸리거든 \"죄인들이\"~ㅎㅎㅎ 재미보고 털리고 그치~~~?     0\n",
       "4241  아버지는 내재된 악마들을 다룰 정신적 힘을 가지고 있지 않았다.\" 이 말한마디가 사...     1\n",
       "4283  댓글 중 \"선동 당해서 촞불든 개돼지 홍어들도 단죄를 받아야 할 공범자들이다\"에100ㅂ!     0\n",
       "5000  스파이 제안받고 살해 안당하는 법1. 처음에 스파이 제안을 받았을때 \"중국을 위해서...     0\n",
       "5521    \"국방부 \"까지 ㅡㄱ ㅐ 엿같은 ㅈ ㅣ랄주댕이...좌빨에서 ㅡ인민군대로 ㅡ가려는건가?     0\n",
       "5866  쌩뚱맞게 60대최반엌 치매라니 그것도 곱게 사는 사모님이- -\" 알콜중독도 아니고 ...     0\n",
       "6477  페미메퇘지쿵쾅년인 메갈페미들은 니들이 좋아하는 싫어요 ㄱㄱ제발부탁해~~\"일반 여성\"...     0\n",
       "6538  아니 ㅆㅂ 그런 \"카더라\"가 넘쳐난다고 그거에 대해서 혹시 댓글게이는 뭔가 아는거 ...     0\n",
       "6771  저 때 투니버스에서 코요태 짧게 인터뷰 했었는데 김종민이 \"노래는 뭐 신지가 다 하...     1\n",
       "6932                개 족 가튼 국방부의 \"휴기연장콜센터\"발족을 축하한다 ㅆ ㅂ..     0\n",
       "7199  민족적 자존심과 애국심을 갖고 국산품 이용합시다 . . . \"겸손\"한 마음으로 재산...     1\n",
       "7252  아나운서는 목표가 아니었지ㅋㅋ재벌하고 결혼하자마자 바로 은퇴하네ㅋㅋ무슨 인터뷰한 거...     0\n",
       "7270  결국 준영과 다솜은 바람을 피게되고 무인도로 떠난다에 한표 ㅋㅋㅋ 자연인이 되어 \"...     1\n",
       "7480  지금 연락하는 여자랑 폰섹 엄청 많이했는데만나서 호텔 들어가서침대에 서로 마주보고 ...     0\n",
       "7499  몽골한테 \"최근에\" 250년간 지배당하고 집단강간을 당했는데 동양피가 하나도 안섞였...     0\n",
       "7887  뭐 선천적으로 여성스럽거나 여자역할을 하고 싶어하는 동성애자들 그럴 수 있다고는 생...     0\n",
       "9666          ㄹㅇ 시발 그냥 \"다른 진로 생각해 보세요\"라고만 했어도 욕 안처 먹었지.     0\n",
       "9698                               간만에 이단어가 떠오르는군 \"이뭐병\"     0\n",
       "9875  노라조 \"형\"이란 노래로 힘들 때 위로를 받곤 했습니다. 앞으로도 노라조라는 이름으...     1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_data = data1[data1['label'].isnull()]\n",
    "null_data['label'] = null_data['content'].str.split('\\t').str[1]\n",
    "null_data['content'] = null_data['content'].str.split('\\t').str[0]\n",
    "null_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "def5a22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이종석 한효주 나오는 드라마 이후로 드라마 안봤다. 2년전인가?? 좀 신선했었지. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>씨바알..노무노무 술프노... 오늘 저녁은 꽂등심이다ㅠㅜ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>짱깨 꺼라ㅡ패쓰</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그들의 사생활 ~ 고인이된 설리를 위해서라도 모두 조용하길 지금 누굴 탓한다고 무슨...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>아무리 법이 뭣같아도 무슨 자격으로 개인의 신상정보를 불특정 다수에게 공개하는지 도...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>몽골한테 \"최근에\" 250년간 지배당하고 집단강간을 당했는데 동양피가 하나도 안섞였...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>뭐 선천적으로 여성스럽거나 여자역할을 하고 싶어하는 동성애자들 그럴 수 있다고는 생...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>ㄹㅇ 시발 그냥 \"다른 진로 생각해 보세요\"라고만 했어도 욕 안처 먹었지.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>간만에 이단어가 떠오르는군 \"이뭐병\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>노라조 \"형\"이란 노래로 힘들 때 위로를 받곤 했습니다. 앞으로도 노라조라는 이름으...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  label\n",
       "0     이종석 한효주 나오는 드라마 이후로 드라마 안봤다. 2년전인가?? 좀 신선했었지. ...      0\n",
       "1                       씨바알..노무노무 술프노... 오늘 저녁은 꽂등심이다ㅠㅜ      0\n",
       "2                                              짱깨 꺼라ㅡ패쓰      0\n",
       "3     그들의 사생활 ~ 고인이된 설리를 위해서라도 모두 조용하길 지금 누굴 탓한다고 무슨...      1\n",
       "4     아무리 법이 뭣같아도 무슨 자격으로 개인의 신상정보를 불특정 다수에게 공개하는지 도...      1\n",
       "...                                                 ...    ...\n",
       "9995  몽골한테 \"최근에\" 250년간 지배당하고 집단강간을 당했는데 동양피가 하나도 안섞였...      0\n",
       "9996  뭐 선천적으로 여성스럽거나 여자역할을 하고 싶어하는 동성애자들 그럴 수 있다고는 생...      0\n",
       "9997          ㄹㅇ 시발 그냥 \"다른 진로 생각해 보세요\"라고만 했어도 욕 안처 먹었지.      0\n",
       "9998                               간만에 이단어가 떠오르는군 \"이뭐병\"      0\n",
       "9999  노라조 \"형\"이란 노래로 힘들 때 위로를 받곤 했습니다. 앞으로도 노라조라는 이름으...      1\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.concat([data1, null_data])\n",
    "df1.dropna(axis=0, inplace=True)\n",
    "df1 = df1.astype({'label':'int'})\n",
    "df1 = df1.reset_index(drop=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e55f6561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7896 entries, 0 to 7895\n",
      "Data columns (total 4 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   comments             7896 non-null   object\n",
      " 1   contain_gender_bias  7896 non-null   bool  \n",
      " 2   bias                 7896 non-null   object\n",
      " 3   hate                 7896 non-null   object\n",
      "dtypes: bool(1), object(3)\n",
      "memory usage: 192.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data2 = pd.read_csv('C:/Users/Haejin Lee/OneDrive/바탕 화면/세미 프로젝트/data/data2.csv', sep='\\t')\n",
    "data2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4494788",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.drop(['contain_gender_bias', 'bias'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecba2fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "none         3486\n",
       "offensive    2499\n",
       "hate         1911\n",
       "Name: hate, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2['hate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30ed1522",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.replace({'hate':0, 'none': 1, 'offensive':0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1d0ff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data2.rename(columns={'comments':'content', 'hate':'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8c82d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4410\n",
       "1    3486\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1f212f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, data2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fcc4486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 17896 entries, 0 to 7895\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   content  17896 non-null  object\n",
      " 1   label    17896 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 419.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efab50b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이종석 한효주 나오는 드라마 이후로 드라마 안봤다. 2년전인가?? 좀 신선했었지. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>씨바알..노무노무 술프노... 오늘 저녁은 꽂등심이다ㅠㅜ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>짱깨 꺼라ㅡ패쓰</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그들의 사생활 ~ 고인이된 설리를 위해서라도 모두 조용하길 지금 누굴 탓한다고 무슨...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>아무리 법이 뭣같아도 무슨 자격으로 개인의 신상정보를 불특정 다수에게 공개하는지 도...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7891</th>\n",
       "      <td>힘내세요~ 응원합니다!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7892</th>\n",
       "      <td>힘내세요~~삼가 고인의 명복을 빕니다..</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7893</th>\n",
       "      <td>힘내세용 ^^ 항상 응원합니닷 ^^ !</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7894</th>\n",
       "      <td>힘내소...연기로 답해요.나도 53살 인데 이런일 저런일 다 있더라구요.인격을 믿습...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7895</th>\n",
       "      <td>힘들면 관뒀어야지 그게 현명한거다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17896 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  label\n",
       "0     이종석 한효주 나오는 드라마 이후로 드라마 안봤다. 2년전인가?? 좀 신선했었지. ...      0\n",
       "1                       씨바알..노무노무 술프노... 오늘 저녁은 꽂등심이다ㅠㅜ      0\n",
       "2                                              짱깨 꺼라ㅡ패쓰      0\n",
       "3     그들의 사생활 ~ 고인이된 설리를 위해서라도 모두 조용하길 지금 누굴 탓한다고 무슨...      1\n",
       "4     아무리 법이 뭣같아도 무슨 자격으로 개인의 신상정보를 불특정 다수에게 공개하는지 도...      1\n",
       "...                                                 ...    ...\n",
       "7891                                      힘내세요~ 응원합니다!!      1\n",
       "7892                             힘내세요~~삼가 고인의 명복을 빕니다..      1\n",
       "7893                              힘내세용 ^^ 항상 응원합니닷 ^^ !      1\n",
       "7894  힘내소...연기로 답해요.나도 53살 인데 이런일 저런일 다 있더라구요.인격을 믿습...      1\n",
       "7895                                 힘들면 관뒀어야지 그게 현명한거다      1\n",
       "\n",
       "[17896 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66cea871",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = df[df['label'] == 0]\n",
    "df_1 = df[df['label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97555415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이종석 한효주 나오는 드라마 이후로 드라마 안봤다. 2년전인가?? 좀 신선했었지. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>씨바알..노무노무 술프노... 오늘 저녁은 꽂등심이다ㅠㅜ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>짱깨 꺼라ㅡ패쓰</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>다음도 들어와라하고...다른 의견내는 유튜버 목 자르고....추아줌마 꺼 여기저기서...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>나경아 젖깐사진이나 인스타에 좀올려라 물좀빼게</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7879</th>\n",
       "      <td>히잌! 기저귀 찬 년들이 군대 군대 주댕이 털고 자빠졌노ㅋ( ° ͜ʖ͡°)╭∩╮</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7880</th>\n",
       "      <td>히트곡이 없는데 추억팔이가되는 놀라운 조선식 방송국연예매니징ㅋㅋ 기획사 소속사 걍 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7881</th>\n",
       "      <td>히트작이래봐야 미사, 발리 두개 정도가 다고 연기력도 그저 그런 수준으로 배우로서 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7882</th>\n",
       "      <td>힘내라 이쁜 혜선아 다음엔 저런인간 만나지 말고^^;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7887</th>\n",
       "      <td>힘내세요 한고은님! btw 아래 한남충 글 뭐냐??풉...평생 연애하나 못하고 홀애...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9410 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  label\n",
       "0     이종석 한효주 나오는 드라마 이후로 드라마 안봤다. 2년전인가?? 좀 신선했었지. ...      0\n",
       "1                       씨바알..노무노무 술프노... 오늘 저녁은 꽂등심이다ㅠㅜ      0\n",
       "2                                              짱깨 꺼라ㅡ패쓰      0\n",
       "5     다음도 들어와라하고...다른 의견내는 유튜버 목 자르고....추아줌마 꺼 여기저기서...      0\n",
       "7                             나경아 젖깐사진이나 인스타에 좀올려라 물좀빼게      0\n",
       "...                                                 ...    ...\n",
       "7879       히잌! 기저귀 찬 년들이 군대 군대 주댕이 털고 자빠졌노ㅋ( ° ͜ʖ͡°)╭∩╮      0\n",
       "7880  히트곡이 없는데 추억팔이가되는 놀라운 조선식 방송국연예매니징ㅋㅋ 기획사 소속사 걍 ...      0\n",
       "7881  히트작이래봐야 미사, 발리 두개 정도가 다고 연기력도 그저 그런 수준으로 배우로서 ...      0\n",
       "7882                      힘내라 이쁜 혜선아 다음엔 저런인간 만나지 말고^^;      0\n",
       "7887  힘내세요 한고은님! btw 아래 한남충 글 뭐냐??풉...평생 연애하나 못하고 홀애...      0\n",
       "\n",
       "[9410 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd765435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그들의 사생활 ~ 고인이된 설리를 위해서라도 모두 조용하길 지금 누굴 탓한다고 무슨...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>아무리 법이 뭣같아도 무슨 자격으로 개인의 신상정보를 불특정 다수에게 공개하는지 도...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>여자들도 아무한테나 자기야라고하는사람있는데 그것도성희롱인것같은데요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>지연이 얼굴은 더 배우같네...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>건축학 개론 지금 다시 봤는데 솔직히 건축학 개론 보다는 아닙니다ㅋ 건축학 개론은 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7891</th>\n",
       "      <td>힘내세요~ 응원합니다!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7892</th>\n",
       "      <td>힘내세요~~삼가 고인의 명복을 빕니다..</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7893</th>\n",
       "      <td>힘내세용 ^^ 항상 응원합니닷 ^^ !</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7894</th>\n",
       "      <td>힘내소...연기로 답해요.나도 53살 인데 이런일 저런일 다 있더라구요.인격을 믿습...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7895</th>\n",
       "      <td>힘들면 관뒀어야지 그게 현명한거다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8486 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  label\n",
       "3     그들의 사생활 ~ 고인이된 설리를 위해서라도 모두 조용하길 지금 누굴 탓한다고 무슨...      1\n",
       "4     아무리 법이 뭣같아도 무슨 자격으로 개인의 신상정보를 불특정 다수에게 공개하는지 도...      1\n",
       "6                  여자들도 아무한테나 자기야라고하는사람있는데 그것도성희롱인것같은데요      1\n",
       "9                                     지연이 얼굴은 더 배우같네...      1\n",
       "10    건축학 개론 지금 다시 봤는데 솔직히 건축학 개론 보다는 아닙니다ㅋ 건축학 개론은 ...      1\n",
       "...                                                 ...    ...\n",
       "7891                                      힘내세요~ 응원합니다!!      1\n",
       "7892                             힘내세요~~삼가 고인의 명복을 빕니다..      1\n",
       "7893                              힘내세용 ^^ 항상 응원합니닷 ^^ !      1\n",
       "7894  힘내소...연기로 답해요.나도 53살 인데 이런일 저런일 다 있더라구요.인격을 믿습...      1\n",
       "7895                                 힘들면 관뒀어야지 그게 현명한거다      1\n",
       "\n",
       "[8486 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b946faf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3466d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0['content'] = df_0['content'].str.replace(pat=r'[^\\w]', repl=r' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f36693a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(['은', '는', '이', '가', '하', '아', '것', '들', '의', '있', '되', '수', '보', '주', '등', '한'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bc6a502",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "893d611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(content, okt, remove_stopwords=False, stop_words=[]) :\n",
    "    word_content = okt.morphs(content, stem=True)\n",
    "    \n",
    "    if remove_stopwords :\n",
    "        word_content = [token for token in word_content if not token in stop_words]\n",
    "    \n",
    "    return word_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "931a3be8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['이종석',\n",
       "  '한효주',\n",
       "  '나오다',\n",
       "  '드라마',\n",
       "  '이후',\n",
       "  '로',\n",
       "  '드라마',\n",
       "  '안',\n",
       "  '보다',\n",
       "  '2년',\n",
       "  '전인가',\n",
       "  '좀',\n",
       "  '신선하다',\n",
       "  '근데',\n",
       "  '이렇다',\n",
       "  '개막',\n",
       "  '장',\n",
       "  '드라마',\n",
       "  '도대체',\n",
       "  '누가',\n",
       "  '보다',\n",
       "  '면',\n",
       "  '변태',\n",
       "  '보다',\n",
       "  '이다',\n",
       "  '정상',\n",
       "  '적',\n",
       "  '인',\n",
       "  '사람',\n",
       "  '채널',\n",
       "  '을',\n",
       "  '돌리다',\n",
       "  '되다'],\n",
       " ['씨', '바알', '노무', '노무', '술프노', '오늘', '저녁', '꽂다', '등심', '이다', 'ㅠㅜ'],\n",
       " ['짱깨', '끄다', 'ㅡ', '패쓰'],\n",
       " ['다음',\n",
       "  '도',\n",
       "  '들어오다',\n",
       "  '하다',\n",
       "  '다른',\n",
       "  '의견',\n",
       "  '내다',\n",
       "  '유튜버',\n",
       "  '목',\n",
       "  '자르다',\n",
       "  '추',\n",
       "  '아줌마',\n",
       "  '끄다',\n",
       "  '여기저기',\n",
       "  '서',\n",
       "  '진술',\n",
       "  '나오니',\n",
       "  '무슨',\n",
       "  '기강',\n",
       "  '감찰',\n",
       "  '이니',\n",
       "  '하다',\n",
       "  '협박',\n",
       "  '들어가다',\n",
       "  '댓글',\n",
       "  '에',\n",
       "  '중국',\n",
       "  '러시아',\n",
       "  '욕',\n",
       "  '하다',\n",
       "  '사람',\n",
       "  '이제',\n",
       "  '아가리',\n",
       "  '닥치다',\n",
       "  '우리나라',\n",
       "  '도',\n",
       "  '똑같이',\n",
       "  '되어다'],\n",
       " ['나경', '젖', '깔다', '사진', '이나', '인스타', '에', '좀', '올리다', '물좀', '빼다']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt = Okt()\n",
    "clean_df_0 = []\n",
    "\n",
    "for content in df_0['content'] :\n",
    "    if type(content) == str :\n",
    "        clean_df_0.append(preprocessing(content, okt, remove_stopwords=True, stop_words=stop_words))\n",
    "    else :\n",
    "        clean_df_0.append([])\n",
    "\n",
    "clean_df_0[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c35843a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kss in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (4.5.1)\n",
      "Requirement already satisfied: pecab in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from kss) (1.0.8)\n",
      "Requirement already satisfied: regex in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from kss) (2022.7.9)\n",
      "Requirement already satisfied: networkx in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from kss) (2.8.4)\n",
      "Requirement already satisfied: emoji==1.2.0 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from kss) (1.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from pecab->kss) (1.21.5)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from pecab->kss) (11.0.0)\n",
      "Requirement already satisfied: pytest in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from pecab->kss) (7.1.2)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from pytest->pecab->kss) (21.4.0)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from pytest->pecab->kss) (1.1.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from pytest->pecab->kss) (21.3)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from pytest->pecab->kss) (1.0.0)\n",
      "Requirement already satisfied: py>=1.8.2 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from pytest->pecab->kss) (1.11.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from pytest->pecab->kss) (2.0.1)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from pytest->pecab->kss) (1.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from pytest->pecab->kss) (0.4.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from packaging->pytest->pecab->kss) (3.0.9)\n",
      "Requirement already satisfied: konlpy in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from konlpy) (4.9.1)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from konlpy) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from konlpy) (1.21.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from JPype1>=0.7.0->konlpy) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from packaging->JPype1>=0.7.0->konlpy) (3.0.9)\n",
      "Requirement already satisfied: soynlp in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (0.0.493)\n",
      "Requirement already satisfied: psutil>=5.0.1 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from soynlp) (5.9.0)\n",
      "Requirement already satisfied: numpy>=1.12.1 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from soynlp) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from soynlp) (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from soynlp) (1.9.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->soynlp) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->soynlp) (1.1.0)\n",
      "Requirement already satisfied: gensim in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from gensim) (1.21.5)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from gensim) (1.9.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: jamo in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (4.26.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from transformers) (0.12.0)\n",
      "Requirement already satisfied: requests in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\haejin lee\\anaconda3\\lib\\site-packages (0.1.97)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement hanspell (from versions: none)\n",
      "ERROR: No matching distribution found for hanspell\n"
     ]
    }
   ],
   "source": [
    "# ! pip install pykospacing\n",
    "! pip install kss\n",
    "! pip install konlpy\n",
    "! pip install soynlp\n",
    "# git clone https://github.com/kakao/khaiii.git # khaii 설치 방법 참조\n",
    "! pip install gensim\n",
    "! pip install jamo\n",
    "! pip install transformers\n",
    "! pip install sentencepiece\n",
    "! pip install hanspell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98d3d2a",
   "metadata": {},
   "source": [
    "# 코사인 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21ec1d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "947d663a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7329</th>\n",
       "      <td>토니스타크 &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 방탄소년단</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8187</th>\n",
       "      <td>구혜선 섹시하지 않은 젖꼭지였구나... 실망..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8156</th>\n",
       "      <td>응 일베 개새끼^^</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>저런것들은... 믹서기에 넣고 돌려야 함</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4016</th>\n",
       "      <td>아들 왜나오냐 ㅉㅉ 완전 등골빼먹는 캥거루족</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         content  label\n",
       "7329      토니스타크 >>>>>>>>>> 방탄소년단      1\n",
       "8187  구혜선 섹시하지 않은 젖꼭지였구나... 실망..      0\n",
       "8156                  응 일베 개새끼^^      0\n",
       "2589      저런것들은... 믹서기에 넣고 돌려야 함      0\n",
       "4016    아들 왜나오냐 ㅉㅉ 완전 등골빼먹는 캥거루족      0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set/ test set 나누기\n",
    "train = df.sample(frac=0.8, random_state=42)\n",
    "test = df.drop(train.index)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25356721",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14317 entries, 7329 to 7355\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   content  14317 non-null  object\n",
      " 1   label    14317 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 335.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede93a78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! pip install git+https://github.com/haven-jeon/PyKoSpacing.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b383dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185                      ㅅㅅ 한게 자랑 ㅈㅅ로 그것도\n",
      "185    이건우 저 저 아직도 때리고 있네 다음 주 까지 때릴 기세여 \n",
      "Name: content, dtype: object\n",
      "185                     ㅅㅅ 한게 자랑 ㅈㅅ로 그것도\n",
      "185    이건우 저 저 아직도 때리고 있네,다음 주 까지 때릴 기세여\n",
      "Name: content, dtype: object\n",
      "185                     ㅅㅅ 한게 자랑 ㅈㅅ로 그것도\n",
      "185    이건우 저 저 아직도 때리고 있네,다음 주 까지 때릴 기세여\n",
      "Name: content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 특수문자 제거\n",
    "import re\n",
    "def cleanse(text):\n",
    "    pattern = re.compile(r'\\s+')\n",
    "    text = re.sub(pattern, ' ', text)\n",
    "    text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣa-zA-Z0-9]', ' ', text)\n",
    "    return text\n",
    "train['content'] = train['content'].apply(cleanse)\n",
    "print(train['content'][185])\n",
    "\n",
    "## 띄어쓰기\n",
    "# from pykospacing import spacing\n",
    "# train['content'] = train['content'].apply(spacing)\n",
    "# print(train['content'][185])\n",
    "\n",
    "# 문장 분리\n",
    "import kss\n",
    "train['content'] = train['content'].apply(kss.split_sentences)\n",
    "train['content'] = [','.join(map(str, ls)) for ls in train['content']]\n",
    "print(train['content'][185])\n",
    "\n",
    "# 중복 제거\n",
    "from soynlp.normalizer import *\n",
    "train['content'] = [repeat_normalize(comment, num_repeats=2) for comment in train['content']]\n",
    "print(train['content'][185])\n",
    "\n",
    "X_train = train['content']\n",
    "X_test = test['content']\n",
    "y_train = train['label']\n",
    "y_test = test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85efdc0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6784 7533 \n",
      " sum: 14317\n"
     ]
    }
   ],
   "source": [
    "# 트레인 데이터 레이블대로 분류\n",
    "none_df = train[train['label'] == 1]['content']\n",
    "hate_df = train[train['label'] == 0]['content']\n",
    "print(len(none_df), len(hate_df), \"\\n\",\n",
    "      \"sum: {}\".format(sum([len(none_df), len(hate_df)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "338cd350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6784, 53086), (7533, 53086))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TfIdf 벡터라이즈\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# 훈련 데이터 전체 벡터라이즈 fit\n",
    "tfidf_vectorizer.fit(train['content'])\n",
    "\n",
    "# 각각 레이블 벡터라이즈 transform\n",
    "none_matrix = tfidf_vectorizer.transform(none_df)\n",
    "hate_matrix = tfidf_vectorizer.transform(hate_df)\n",
    "\n",
    "none_matrix.shape, hate_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c322ebad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53086, 53086)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각각의 평균 벡터값(위치) 산출\n",
    "none_vec = []\n",
    "hate_vec = []\n",
    "\n",
    "for i in range(none_matrix.shape[1]):\n",
    "    none_vec.append(none_matrix[:,i].mean())\n",
    "\n",
    "    \n",
    "for i in range(hate_matrix.shape[1]):\n",
    "    hate_vec.append(hate_matrix[:,i].mean())\n",
    "\n",
    "# 벡터라이즈 잘 되었는지 길이 확인\n",
    "len(none_vec), len(hate_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1ae208b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1022, 53086)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 어레이 형태로 변환\n",
    "none_vec = np.array(none_vec)\n",
    "hate_vec = np.array(hate_vec)\n",
    "\n",
    "# 2차원 어레이로 변환\n",
    "none_vec = none_vec.reshape(1, -1)\n",
    "hate_vec = hate_vec.reshape(1, -1)\n",
    "\n",
    "# 테스트 코멘트 벡터라이즈 적용\n",
    "test_matrix = tfidf_vectorizer.transform(test['content'])\n",
    "test_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac3b6ad0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 코멘트 <-> 각 레이블 간의 유사도 측정 후 가장 유사한 레이블 산출\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "labels = []\n",
    "\n",
    "for i in range(test_matrix.shape[0]):\n",
    "    distances = {cosine_similarity(test_matrix[i,:], none_vec)[0][0] : 1,\n",
    "                 cosine_similarity(test_matrix[i,:], hate_vec)[0][0] : 0}\n",
    "    labels.append( distances[max(distances.keys())] )\n",
    "    \n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85086f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc : 0.7671232876712328 \n",
      "F1 Score : 0.7670153256704981\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "print('Acc : {}'.format((accuracy_score(test['label'], labels))), '\\n'\n",
    "      'F1 Score : {}'.format(f1_score(test['label'], labels, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4757be0e",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aed047c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "# from khaiii import KhaiiiApi; k = KhaiiiApi()\n",
    "from konlpy.tag import Okt; t = Okt()\n",
    "from konlpy.utils import pprint\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6b079dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7e071eca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['content'].to_csv(\"content.txt\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3cba1723",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['이종석 한효주 나오는 드라마 이후로 드라마 안봤다. 2년전인가?? 좀 신선했었지. 근데 이런 개막장 드라마는 도대체 누가 보느냐면 변태들이 보는 것이다. 정상적인 사람들은 채널을 돌리게 된다.',\n",
       " '씨바알..노무노무 술프노... 오늘 저녁은 꽂등심이다ㅠㅜ',\n",
       " '짱깨 꺼라ㅡ패쓰',\n",
       " '그들의 사생활 ~ 고인이된 설리를 위해서라도 모두 조용하길 지금 누굴 탓한다고 무슨소용이있다고',\n",
       " '아무리 법이 뭣같아도 무슨 자격으로 개인의 신상정보를 불특정 다수에게 공개하는지 도저히 이해가 안되네요 법을 바꾸기 위해 노력하세요 저런 능력으로 불법적인 일을 공공의 이익으로 포장하지 마시구요',\n",
       " '다음도 들어와라하고...다른 의견내는 유튜버 목 자르고....추아줌마 꺼 여기저기서 진술나오니...무슨 기강감찰이니 하며 협박들어가고..... 댓글에 중국 러시아 욕하는 사람들 이제 아가리 닥쳐라. 우리나라도 똑같이 되었다.',\n",
       " '여자들도 아무한테나 자기야라고하는사람있는데 그것도성희롱인것같은데요',\n",
       " '나경아 젖깐사진이나 인스타에 좀올려라 물좀빼게',\n",
       " '어린시절 가정교육 못 받은 애들은 절대 그 본성을 숨길수없지']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"C:/Users/Haejin Lee/Downloads/content.txt\",encoding='UTF8') as f:\n",
    "    text = f.readlines()\n",
    "text = [txt.replace(\"\\n\", \"\") for txt in text]\n",
    "text[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b74849fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenized_data = []\n",
    "for sentence in text:\n",
    "    tokenized_data.append(t.morphs(sentence, stem=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "453bf256",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding = Word2Vec(tokenized_data, vector_size=100, window=5, min_count=5, workers=4)\n",
    "embedding.save('./comments100.model')\n",
    "# sentences : 각 문장 마다 하나의 토큰 list를 생성하며 토큰 list의 개수는 문장 개수 n개 만큼 생성하여 sentences에 저장해둠\n",
    "# vextor_size : word 벡터 차원\n",
    "# window : 현재 단어와 예측 단어의 최대 거리\n",
    "# negative : 0으로 두면 negative smapling을 하지하지 않으며, 0보다 큰 값이면 negative sampling을 수행함\n",
    "# min_count : min_count의 빈도수보다 낮은 빈도수인 단어는 무시합니다.\n",
    "# worker : 모델 생성시 사용할 쓰레드 개수\n",
    "# sg : sg 값이 1이면 skip-gram이지만 그렇지 않으면 CBOW 알고리즘을 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9bfa110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('./comments100.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0554509a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('말', 0.9658010005950928),\n",
       " ('그렇다', 0.9614135026931763),\n",
       " ('돈', 0.9500884413719177),\n",
       " ('연예인', 0.9462057948112488),\n",
       " ('짓', 0.9437451958656311),\n",
       " ('왜', 0.9408250451087952),\n",
       " ('지다', 0.9401247501373291),\n",
       " ('그냥', 0.9398123025894165),\n",
       " ('ㅋㅋㅋ', 0.936764121055603),\n",
       " ('너', 0.9345120787620544),\n",
       " ('존나', 0.9310834407806396),\n",
       " ('면상', 0.9304425120353699),\n",
       " ('쿵쾅', 0.9304224252700806),\n",
       " ('난리', 0.929409921169281),\n",
       " ('한남', 0.9290915727615356),\n",
       " ('염치', 0.928621768951416),\n",
       " ('걔네', 0.9284080862998962),\n",
       " ('지랄', 0.9279258251190186),\n",
       " ('한테', 0.9273404479026794),\n",
       " ('네티즌', 0.927315354347229),\n",
       " ('ㅂㄷㅂㄷ', 0.9267259836196899),\n",
       " ('꼬이다', 0.9251532554626465),\n",
       " ('끼리', 0.925150454044342),\n",
       " ('럴', 0.9250636100769043),\n",
       " ('노인', 0.9244217276573181),\n",
       " ('안심', 0.9243153929710388),\n",
       " ('노처녀', 0.9240260124206543),\n",
       " ('용접', 0.9237282872200012),\n",
       " ('맞다', 0.9234192967414856),\n",
       " ('페미', 0.9234135746955872)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=[\"욕\"], topn=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "00377a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'김희선',\n",
       " '땐',\n",
       " '변화',\n",
       " '독하다',\n",
       " '파악',\n",
       " '이기다',\n",
       " '공무원',\n",
       " '아가',\n",
       " '시나',\n",
       " '두',\n",
       " '미리',\n",
       " '족',\n",
       " '겨',\n",
       " '만찬',\n",
       " '쥬',\n",
       " '깨어나다',\n",
       " '적도',\n",
       " '거론',\n",
       " '컴퓨터',\n",
       " 'ㅇㅈㄹ',\n",
       " '중기',\n",
       " '담다',\n",
       " '진우',\n",
       " '일베',\n",
       " '어리다',\n",
       " '기록',\n",
       " '멋',\n",
       " '앞서',\n",
       " '간만',\n",
       " '청소',\n",
       " '우익',\n",
       " '!!\"',\n",
       " '쌍둥이',\n",
       " '가만',\n",
       " '1',\n",
       " '심정',\n",
       " '결과',\n",
       " '나름',\n",
       " '합류',\n",
       " '부정',\n",
       " '신성록',\n",
       " '주예지',\n",
       " '작년',\n",
       " '6',\n",
       " '널리',\n",
       " '한지혜',\n",
       " '세월호',\n",
       " '천명훈',\n",
       " '기사',\n",
       " '👍',\n",
       " '길이',\n",
       " '지시',\n",
       " '온몸',\n",
       " '유독',\n",
       " '걍',\n",
       " '체',\n",
       " '공인',\n",
       " '소린',\n",
       " '돌파',\n",
       " '스럽다',\n",
       " '때',\n",
       " '앞',\n",
       " '학창시절',\n",
       " '개이득',\n",
       " '인증',\n",
       " '지연',\n",
       " '한데',\n",
       " '것',\n",
       " '어쩌',\n",
       " '10',\n",
       " '방식',\n",
       " '존잘',\n",
       " '어디',\n",
       " '로서',\n",
       " '마닷',\n",
       " '홍윤',\n",
       " '갈리다',\n",
       " '이끌다',\n",
       " '하나요',\n",
       " '성격',\n",
       " '손담비',\n",
       " '흑역사',\n",
       " '넘치다',\n",
       " '께',\n",
       " '해봤다',\n",
       " '이영애',\n",
       " '의심스럽다',\n",
       " '영향',\n",
       " '모자',\n",
       " '늙음',\n",
       " '정은',\n",
       " '끊다',\n",
       " '수출',\n",
       " '자',\n",
       " '떡',\n",
       " '퇴물',\n",
       " '단어',\n",
       " '보지',\n",
       " '닭',\n",
       " '선예',\n",
       " '전체',\n",
       " '소속사',\n",
       " '내내',\n",
       " 'xx',\n",
       " '적응',\n",
       " '짱꼴라',\n",
       " 'x',\n",
       " '이고',\n",
       " '사실',\n",
       " '조선시대',\n",
       " '기본',\n",
       " '별거',\n",
       " '체널',\n",
       " '안재현',\n",
       " '유일하다',\n",
       " '완전',\n",
       " '단독',\n",
       " '성향',\n",
       " '빨다',\n",
       " '심다',\n",
       " '마냥',\n",
       " '실',\n",
       " '정선',\n",
       " '오죽하다',\n",
       " '뭐라다',\n",
       " '어쩔',\n",
       " '멘트',\n",
       " '지만',\n",
       " 'ㅋㅋㅋㅋㅋㅋ',\n",
       " '커버',\n",
       " '교회',\n",
       " '위치',\n",
       " '자라',\n",
       " '밀다',\n",
       " '예수님',\n",
       " '라는',\n",
       " '실체',\n",
       " '삐지다',\n",
       " '배우다',\n",
       " '동안',\n",
       " '한잔',\n",
       " '돌대가리',\n",
       " '탈세',\n",
       " '값',\n",
       " '선동',\n",
       " '김제동',\n",
       " '사거리',\n",
       " '남아',\n",
       " '쳐다보다',\n",
       " '전라디언',\n",
       " '돋다',\n",
       " '올라가다',\n",
       " '내주다',\n",
       " '같이',\n",
       " 'ㅇㅂ',\n",
       " '옆',\n",
       " '존예',\n",
       " '삼촌',\n",
       " '홍진경',\n",
       " '노',\n",
       " '파이팅',\n",
       " '피자',\n",
       " '테러',\n",
       " '굶다',\n",
       " '빼먹다',\n",
       " '수많다',\n",
       " '이따',\n",
       " '방사',\n",
       " '흠',\n",
       " '신동욱',\n",
       " '국보',\n",
       " '소문',\n",
       " '올림픽',\n",
       " '차별',\n",
       " '다니다',\n",
       " '컷',\n",
       " '걔',\n",
       " '인들',\n",
       " '작가',\n",
       " '가도',\n",
       " '무례하다',\n",
       " '자임',\n",
       " '다해',\n",
       " '중개사',\n",
       " '진정',\n",
       " '먹다',\n",
       " '위',\n",
       " '백종원',\n",
       " '위대하다',\n",
       " '선씨',\n",
       " '~~',\n",
       " '형사',\n",
       " '캐다',\n",
       " '포장',\n",
       " '똑바로',\n",
       " '바퀴벌레',\n",
       " '!!!!!!!!',\n",
       " '글자',\n",
       " '넘어지다',\n",
       " '역쉬',\n",
       " '외도',\n",
       " '신상',\n",
       " '따먹다',\n",
       " '빡치다',\n",
       " '.......',\n",
       " '가난하다',\n",
       " '갖추다',\n",
       " '반일',\n",
       " '본능',\n",
       " '금수',\n",
       " '지드래곤',\n",
       " '에다',\n",
       " '속상하다',\n",
       " '돈맛',\n",
       " '징글징글',\n",
       " '자세하다',\n",
       " '대수',\n",
       " '정용화',\n",
       " '손잡다',\n",
       " '성우',\n",
       " '금액',\n",
       " '아버지',\n",
       " 'ㅎㅎ',\n",
       " '주차장',\n",
       " '웃기다',\n",
       " '쯤',\n",
       " '90',\n",
       " '진부하다',\n",
       " '배',\n",
       " '하승진',\n",
       " '꼭지',\n",
       " '복권',\n",
       " '저',\n",
       " '영화',\n",
       " '탁재훈',\n",
       " '그간',\n",
       " '함부로',\n",
       " '신동엽',\n",
       " '답',\n",
       " '뇌',\n",
       " '트집',\n",
       " '죄송하다',\n",
       " '버티고',\n",
       " '충격',\n",
       " '84',\n",
       " '이드',\n",
       " '은퇴',\n",
       " '솔로',\n",
       " '호',\n",
       " 'ㄷㄷㄷ',\n",
       " '필립',\n",
       " '한국인',\n",
       " '자상하다',\n",
       " '어찌',\n",
       " '...',\n",
       " '잔인하다',\n",
       " '세균',\n",
       " '갈다',\n",
       " '노친',\n",
       " '혼자',\n",
       " '말아먹다',\n",
       " '예수',\n",
       " '튀다',\n",
       " '기부',\n",
       " 'ㅗㅗ',\n",
       " '끌다',\n",
       " '17',\n",
       " '고딩',\n",
       " '목표',\n",
       " '삼다',\n",
       " '완치',\n",
       " '대리',\n",
       " '달달',\n",
       " '이라니',\n",
       " '저녁',\n",
       " '대하',\n",
       " '부',\n",
       " '비호감',\n",
       " '힐링',\n",
       " '탈',\n",
       " '수지',\n",
       " '유출',\n",
       " '불편하다',\n",
       " '이나라',\n",
       " '노라조',\n",
       " '재상',\n",
       " '문',\n",
       " '판타지',\n",
       " '가든',\n",
       " '틀',\n",
       " '백마',\n",
       " '기대다',\n",
       " '서현진',\n",
       " '바지',\n",
       " '비번',\n",
       " '홍상수',\n",
       " '조아',\n",
       " '진심',\n",
       " '엠비씨',\n",
       " \"'\",\n",
       " '본성',\n",
       " '날다',\n",
       " '콩밥',\n",
       " '이라도',\n",
       " '@.@',\n",
       " '파다',\n",
       " '요',\n",
       " '폐지',\n",
       " '김태리',\n",
       " '갓',\n",
       " '라이프',\n",
       " '소연',\n",
       " '치료',\n",
       " '이유리',\n",
       " '연기자',\n",
       " '보신',\n",
       " '떨어뜨리다',\n",
       " '미추',\n",
       " '감방',\n",
       " '어거지',\n",
       " '달다',\n",
       " '느끼다',\n",
       " '동남아',\n",
       " '망정',\n",
       " '초심',\n",
       " '평점',\n",
       " '차려',\n",
       " '믿다',\n",
       " '및',\n",
       " '아이디',\n",
       " '준',\n",
       " '왠지',\n",
       " 'ㅇㅇ',\n",
       " '부인',\n",
       " '태생',\n",
       " '지성',\n",
       " '퀴',\n",
       " '눈빛',\n",
       " '유도',\n",
       " '언론',\n",
       " '이야기',\n",
       " '음식',\n",
       " '무기',\n",
       " '팔자',\n",
       " '자체',\n",
       " '어도',\n",
       " '은인',\n",
       " '한가인',\n",
       " '존중',\n",
       " '외롭다',\n",
       " '모성애',\n",
       " '설',\n",
       " '녀',\n",
       " '아지',\n",
       " '법안',\n",
       " '자동',\n",
       " '명',\n",
       " '학생',\n",
       " '해결',\n",
       " '판',\n",
       " '대도',\n",
       " '기일',\n",
       " '구속',\n",
       " '까진',\n",
       " '잡다',\n",
       " '편의점',\n",
       " '이빨',\n",
       " '3년',\n",
       " '굳다',\n",
       " '지겹다',\n",
       " '!!!!!',\n",
       " '이소라',\n",
       " '윤소희',\n",
       " '징',\n",
       " '변경',\n",
       " '김범룡',\n",
       " '형제',\n",
       " '가능하다',\n",
       " '취집',\n",
       " '그만하다',\n",
       " '끝내',\n",
       " '일당',\n",
       " '당나라',\n",
       " '여행가',\n",
       " 'ㅗ',\n",
       " '컬',\n",
       " '-',\n",
       " '후진국',\n",
       " '연습생',\n",
       " '늑대',\n",
       " '겁니다',\n",
       " '맛없다',\n",
       " '정신승리',\n",
       " '룩',\n",
       " '오래전',\n",
       " '웬',\n",
       " '지지자',\n",
       " '마이',\n",
       " '140',\n",
       " '바보',\n",
       " '그동안',\n",
       " '순수하다',\n",
       " '음해',\n",
       " '그만',\n",
       " '조세호',\n",
       " '부칸',\n",
       " '주신',\n",
       " '짬뽕',\n",
       " '슈퍼',\n",
       " '구리다',\n",
       " '초밥',\n",
       " '공효진',\n",
       " '인민',\n",
       " '베충',\n",
       " '야',\n",
       " '빙신',\n",
       " '주인',\n",
       " '신다은',\n",
       " '이여',\n",
       " '여기',\n",
       " '목사',\n",
       " '결론',\n",
       " '꺼내다',\n",
       " '남탓',\n",
       " '빤스',\n",
       " '이채',\n",
       " '나문희',\n",
       " '니까',\n",
       " '조개',\n",
       " '옷',\n",
       " '식상하다',\n",
       " '우린',\n",
       " '인하다',\n",
       " '그건',\n",
       " '돈',\n",
       " '독보',\n",
       " '족속',\n",
       " '현상',\n",
       " '연예계',\n",
       " '무당',\n",
       " '김연아',\n",
       " '정준영',\n",
       " '대표',\n",
       " '고로',\n",
       " '용이',\n",
       " '하',\n",
       " '믿음',\n",
       " '같다',\n",
       " '팔이',\n",
       " '통신비',\n",
       " '드리다',\n",
       " '빅',\n",
       " '여친',\n",
       " '장가',\n",
       " '개',\n",
       " '꼰',\n",
       " '영웅',\n",
       " '홀랑',\n",
       " '신봉선',\n",
       " '언제',\n",
       " '여서',\n",
       " '심판',\n",
       " '~!!!',\n",
       " '살림',\n",
       " '한고은',\n",
       " 'bts',\n",
       " '자매',\n",
       " 'ㅡㅡ',\n",
       " '중년',\n",
       " '이영자',\n",
       " '’',\n",
       " '프랜차이즈',\n",
       " '좋다',\n",
       " '결혼식장',\n",
       " '역시',\n",
       " '느낌',\n",
       " '겉',\n",
       " '벌써',\n",
       " '‘',\n",
       " '사단',\n",
       " '살아나다',\n",
       " '빠르다',\n",
       " '정준',\n",
       " '가',\n",
       " '결정',\n",
       " '어쩐',\n",
       " 'ㅈㄴ',\n",
       " '천',\n",
       " '견찰',\n",
       " '죽다',\n",
       " '박진영',\n",
       " '붐',\n",
       " '당사자',\n",
       " '흉',\n",
       " '일지',\n",
       " '나발',\n",
       " '운',\n",
       " '추카',\n",
       " '민주당',\n",
       " '용서',\n",
       " 'ost',\n",
       " '똥폼',\n",
       " '읽다',\n",
       " '흙',\n",
       " '다가',\n",
       " '로또',\n",
       " '뭉치다',\n",
       " '토크',\n",
       " '나혼자산다',\n",
       " '사과문',\n",
       " '푼',\n",
       " '늙다',\n",
       " '고생',\n",
       " '행',\n",
       " '부러지다',\n",
       " '외식',\n",
       " '웹툰',\n",
       " '반칙',\n",
       " '드나들다',\n",
       " '동기부여',\n",
       " '열',\n",
       " '댓',\n",
       " '서울대',\n",
       " '는',\n",
       " '대화',\n",
       " '분야',\n",
       " '국내',\n",
       " '한수민',\n",
       " '채린',\n",
       " '모으다',\n",
       " '맨날',\n",
       " '변태',\n",
       " '커리어',\n",
       " '수산물',\n",
       " '흑',\n",
       " '스텝',\n",
       " '전두환',\n",
       " '지켜보다',\n",
       " '19',\n",
       " '애매하다',\n",
       " '신선하다',\n",
       " '천지',\n",
       " '밖',\n",
       " '연애',\n",
       " '해달라다',\n",
       " '처리',\n",
       " '부끄럽다',\n",
       " '덥다',\n",
       " '후보',\n",
       " '김승현',\n",
       " '와이프',\n",
       " '아아',\n",
       " '진',\n",
       " '방송국',\n",
       " '쌍판',\n",
       " '라서',\n",
       " '려',\n",
       " '님들',\n",
       " '끼치다',\n",
       " '90%',\n",
       " '꾼',\n",
       " '플',\n",
       " '기분',\n",
       " '가나',\n",
       " '사극',\n",
       " '보도',\n",
       " '이를',\n",
       " '명도',\n",
       " '육갑',\n",
       " '빠지다',\n",
       " '문죄인',\n",
       " '깽',\n",
       " '황제',\n",
       " '소재',\n",
       " '불쌍하다',\n",
       " '캐',\n",
       " '짜리몽땅',\n",
       " '재료',\n",
       " '번',\n",
       " '카페',\n",
       " '!!!!!!',\n",
       " 'ㅅㅌㅊ',\n",
       " '시국',\n",
       " '정말',\n",
       " '참다',\n",
       " '사범',\n",
       " '어이없다',\n",
       " '꼴리다',\n",
       " '볼',\n",
       " '대충',\n",
       " '공주',\n",
       " '도경',\n",
       " '심각하다',\n",
       " '먹히다',\n",
       " '베',\n",
       " '간지',\n",
       " '따라가다',\n",
       " '벌금',\n",
       " '싸이',\n",
       " '부장',\n",
       " '네이버',\n",
       " '중딩',\n",
       " '신도',\n",
       " '예의',\n",
       " '근대',\n",
       " '가식',\n",
       " '고만',\n",
       " '한순간',\n",
       " '무릎',\n",
       " '여기저기',\n",
       " '어머님',\n",
       " '...\"',\n",
       " '월드컵',\n",
       " '넌',\n",
       " '쌤',\n",
       " '안보',\n",
       " '어차피',\n",
       " '왕따',\n",
       " '올라오다',\n",
       " '놀이',\n",
       " '아쉬움',\n",
       " '핑크',\n",
       " '정보',\n",
       " '갑질',\n",
       " '일도',\n",
       " '혼외자',\n",
       " '기대하다',\n",
       " '(',\n",
       " '드디어',\n",
       " '오크',\n",
       " '타',\n",
       " '표본',\n",
       " '노래',\n",
       " '투철',\n",
       " '지다',\n",
       " '점',\n",
       " '어렵다',\n",
       " '옥주현',\n",
       " '킬로',\n",
       " '김주혁',\n",
       " '윤미래',\n",
       " '연',\n",
       " '타고나다',\n",
       " '끝',\n",
       " '치네다',\n",
       " '원하다',\n",
       " '마',\n",
       " '만만하다',\n",
       " '동의',\n",
       " '집중',\n",
       " '윤세아',\n",
       " '결혼',\n",
       " '고양이',\n",
       " '지목',\n",
       " '찍',\n",
       " '한은정',\n",
       " '놓치다',\n",
       " '친구',\n",
       " '원호',\n",
       " '박수',\n",
       " '나혼산',\n",
       " '척',\n",
       " '바르다',\n",
       " '감당',\n",
       " '기적',\n",
       " '씨발',\n",
       " '이용',\n",
       " '광대',\n",
       " '부담스럽다',\n",
       " '증거',\n",
       " '추천',\n",
       " '공연',\n",
       " '올해',\n",
       " '맛',\n",
       " '와도',\n",
       " '거슬리다',\n",
       " '안내',\n",
       " '죄인',\n",
       " '1조',\n",
       " '예요',\n",
       " '이루다',\n",
       " '어디서',\n",
       " '전남편',\n",
       " '뜰',\n",
       " '혜성',\n",
       " '오줌',\n",
       " '당',\n",
       " '해',\n",
       " '차라리',\n",
       " '으로써',\n",
       " '자발',\n",
       " '타고',\n",
       " '바하',\n",
       " '짝',\n",
       " '충분하다',\n",
       " '아파트',\n",
       " '만들어지다',\n",
       " '새다',\n",
       " '니애미',\n",
       " '바닥',\n",
       " '부모님',\n",
       " '글',\n",
       " '해명',\n",
       " '무도',\n",
       " '깨지다',\n",
       " '과일',\n",
       " '졸리다',\n",
       " '긋다',\n",
       " '작고',\n",
       " 'k',\n",
       " '.\"',\n",
       " '관대하다',\n",
       " '양',\n",
       " '빽',\n",
       " '원칙',\n",
       " '유행',\n",
       " '천박하다',\n",
       " '공격',\n",
       " '기획',\n",
       " '습',\n",
       " '혜리',\n",
       " '판사',\n",
       " '해주',\n",
       " '서다',\n",
       " '허락',\n",
       " '이태임',\n",
       " '이군',\n",
       " '두껍다',\n",
       " '개다',\n",
       " '율',\n",
       " '끝나다',\n",
       " '미국인',\n",
       " '급여',\n",
       " '입학',\n",
       " '2년',\n",
       " '모자라다',\n",
       " '수',\n",
       " '텐데',\n",
       " '연구소',\n",
       " '친일파',\n",
       " 'ㅁㅈㅎ',\n",
       " '티비',\n",
       " '이건우',\n",
       " '복싱',\n",
       " '김지석',\n",
       " '선택',\n",
       " '가져오다',\n",
       " '대로',\n",
       " '&',\n",
       " '사진',\n",
       " '소지섭',\n",
       " '빈',\n",
       " '기대',\n",
       " '빨갱',\n",
       " '여주',\n",
       " '월세',\n",
       " '남자에게',\n",
       " '독박',\n",
       " 'ㅎㅎㅎㅎ',\n",
       " '행동',\n",
       " '예능인',\n",
       " '하늘나라',\n",
       " '저능',\n",
       " '이따위',\n",
       " '판치다',\n",
       " '공산',\n",
       " '바쁘다',\n",
       " '고현정',\n",
       " '안정',\n",
       " '소스',\n",
       " '진도',\n",
       " '꽁초',\n",
       " '갑자기',\n",
       " '개국',\n",
       " '내려놓다',\n",
       " '이전',\n",
       " '문희준',\n",
       " '비만',\n",
       " '국적',\n",
       " '이미',\n",
       " '년',\n",
       " '문과',\n",
       " '휴가',\n",
       " '이쁘다',\n",
       " '막다',\n",
       " '따다',\n",
       " '잠잠하다',\n",
       " '남규리',\n",
       " '개비',\n",
       " '정준호',\n",
       " '해석',\n",
       " '동거',\n",
       " '만날',\n",
       " '연속',\n",
       " '70',\n",
       " '군인',\n",
       " '명품',\n",
       " '혀',\n",
       " '모욕',\n",
       " '풍상',\n",
       " '제품',\n",
       " '퇴',\n",
       " '강성훈',\n",
       " '대학',\n",
       " '연장',\n",
       " '38',\n",
       " '라이네',\n",
       " '보복',\n",
       " 'ㄷㄷ',\n",
       " '꾸미다',\n",
       " '통계',\n",
       " '조회',\n",
       " '꼬리',\n",
       " '열사',\n",
       " '아가리',\n",
       " '팍팍',\n",
       " '절친',\n",
       " '가르치다',\n",
       " '아끼다',\n",
       " '여자',\n",
       " '세명',\n",
       " '도보',\n",
       " '장난',\n",
       " '병신년',\n",
       " '비정상',\n",
       " '착',\n",
       " '개웃',\n",
       " '수배',\n",
       " '미가',\n",
       " '사악하다',\n",
       " '손승연',\n",
       " '비키다',\n",
       " '싸구려',\n",
       " '준희',\n",
       " '구분',\n",
       " 'ㄴ',\n",
       " '사기',\n",
       " '최',\n",
       " '약하다',\n",
       " '단순하다',\n",
       " '적폐',\n",
       " '국민성',\n",
       " '몰리다',\n",
       " '헤어지다',\n",
       " '채우다',\n",
       " '아이즈',\n",
       " '비다',\n",
       " '레벨',\n",
       " '어르다',\n",
       " '묘',\n",
       " '청춘',\n",
       " '성질',\n",
       " 'cf',\n",
       " '목',\n",
       " '........',\n",
       " '나다',\n",
       " '신자',\n",
       " '열폭',\n",
       " '개발',\n",
       " '노랗다',\n",
       " '묶다',\n",
       " '트럭',\n",
       " '싫어하다',\n",
       " '클라라',\n",
       " '리',\n",
       " '미화',\n",
       " '불가능하다',\n",
       " '용어',\n",
       " '특이하다',\n",
       " '헐다',\n",
       " '조건',\n",
       " '시원하다',\n",
       " '강타',\n",
       " '핀란드',\n",
       " '흔하다',\n",
       " '대역',\n",
       " '님',\n",
       " '20년',\n",
       " '센스',\n",
       " '억',\n",
       " '하은',\n",
       " '발달',\n",
       " '가지가지',\n",
       " '이민',\n",
       " '사과',\n",
       " '배알',\n",
       " '시간',\n",
       " '결혼식',\n",
       " '부치다',\n",
       " '명령',\n",
       " '의미',\n",
       " '구별',\n",
       " '전액',\n",
       " '현재',\n",
       " '감추다',\n",
       " '집착',\n",
       " '양배추',\n",
       " '윤지성',\n",
       " '성범죄자',\n",
       " '만하',\n",
       " '송창의',\n",
       " '200',\n",
       " '드루',\n",
       " '현우',\n",
       " '규제',\n",
       " '설치',\n",
       " '찾아가다',\n",
       " '투어',\n",
       " '이구만',\n",
       " '골빈',\n",
       " '해외',\n",
       " '잘못',\n",
       " '메다',\n",
       " '신념',\n",
       " '유동근',\n",
       " '싸하다',\n",
       " '과학',\n",
       " '귀신',\n",
       " '신경안',\n",
       " '안이',\n",
       " '서열',\n",
       " '???',\n",
       " '잘나가다',\n",
       " '분명하다',\n",
       " '리액션',\n",
       " '방송',\n",
       " '대세',\n",
       " '침',\n",
       " '비위',\n",
       " '넼',\n",
       " '옳다',\n",
       " '우월',\n",
       " '부들',\n",
       " '연하남',\n",
       " '최자',\n",
       " '민가',\n",
       " '미나',\n",
       " 'PC',\n",
       " '죽음',\n",
       " '서태지',\n",
       " '예고',\n",
       " '삶다',\n",
       " '데이트',\n",
       " '육',\n",
       " '수능',\n",
       " '추다',\n",
       " '슬쩍',\n",
       " '쌍욕',\n",
       " '창녀',\n",
       " 'ㄱㅐ',\n",
       " '선미',\n",
       " '게스트',\n",
       " '악마',\n",
       " '응원',\n",
       " '워',\n",
       " '친문',\n",
       " '향수',\n",
       " '아이디어',\n",
       " '다시다',\n",
       " '코요테',\n",
       " '암',\n",
       " '기원',\n",
       " '지',\n",
       " '연기력',\n",
       " '2.5',\n",
       " '답답하다',\n",
       " '영화계',\n",
       " '대장',\n",
       " '만수무강',\n",
       " '희망',\n",
       " '첫째',\n",
       " '갖다',\n",
       " '수로',\n",
       " '레알',\n",
       " '눈물',\n",
       " '최소',\n",
       " '멀리',\n",
       " '대답',\n",
       " '한의사',\n",
       " '미만',\n",
       " '먹이다',\n",
       " '거나',\n",
       " '고재',\n",
       " '기',\n",
       " '재미없다',\n",
       " '비공개',\n",
       " '에게도',\n",
       " '유아인',\n",
       " '낫다',\n",
       " '답변',\n",
       " '버릇',\n",
       " '노출',\n",
       " '사인',\n",
       " '알려지다',\n",
       " '최소한',\n",
       " '구나',\n",
       " '좆망',\n",
       " '....?',\n",
       " '채널',\n",
       " '최수종',\n",
       " ...}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(model.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cf80d149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(words):\n",
    "    # 출력 벡터 초기화\n",
    "    feature_vector = np.zeros(100, dtype=np.float32)\n",
    "    num_words = 0\n",
    "    \n",
    "    # 어휘 사전 준비\n",
    "    index2word_set = set(model.wv.index_to_key)\n",
    "    \n",
    "    for w in words:\n",
    "        if w in index2word_set:\n",
    "            num_words = 1\n",
    "            # 사전에 해당하는 단어에 대해 단어 벡터를 더함\n",
    "            feature_vector = np.add(feature_vector, model.wv[w])\n",
    "            \n",
    "    # 문장의 단어 수만큼 나누어 단어 벡터의 평균값을 문장 벡터로 함\n",
    "    feature_vector = np.divide(feature_vector, num_words)\n",
    "    feature_vectors = np.nan_to_num(feature_vector, copy=False)\n",
    "    return feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "69cf1912",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.8292091e-01,  1.7771583e+00,  5.0872034e-01, -9.2585802e-01,\n",
       "        3.1392360e-01, -1.5881537e+00,  6.1030525e-01,  4.5369878e+00,\n",
       "       -1.2808168e+00, -1.6585873e+00, -2.3160565e-01, -3.1513538e+00,\n",
       "       -1.1773183e+00,  1.5005782e+00,  1.1374034e+00, -1.6556162e+00,\n",
       "        8.1817025e-01, -1.5097834e+00,  3.3857986e-02, -3.2133968e+00,\n",
       "        1.4471855e+00,  3.1858647e-01,  2.0699387e+00, -1.2891749e-01,\n",
       "       -9.6390694e-01, -9.8738596e-03, -6.3106358e-01, -1.5091569e+00,\n",
       "       -1.8213918e+00,  7.1240902e-01,  1.7409936e+00,  1.2692106e-03,\n",
       "        4.7762224e-01, -2.7518795e+00, -4.6953116e-02,  1.9858766e+00,\n",
       "       -7.6574147e-02, -1.4895548e+00, -6.7268258e-01, -2.5443151e+00,\n",
       "        1.9268866e-01, -1.4957455e+00, -1.9526044e-01,  6.7034215e-02,\n",
       "        4.8178098e-01, -1.0898352e+00, -9.7365463e-01, -2.2376335e-01,\n",
       "        3.9710230e-01,  1.2900330e+00,  9.1560757e-01, -1.1795849e+00,\n",
       "       -8.3070832e-01, -8.2995987e-01, -8.3601499e-01,  2.4507447e-01,\n",
       "        1.3254371e+00,  1.2968851e+00, -1.1710613e+00,  2.4804288e-01,\n",
       "        7.5502761e-02,  1.5066330e-01,  1.6577789e-01, -1.1031424e-01,\n",
       "       -2.6446178e+00,  1.1830628e+00,  3.7096977e-01,  1.6372716e+00,\n",
       "       -2.0881116e+00,  1.3580301e+00, -1.0293574e+00,  9.1165888e-01,\n",
       "        1.0081877e+00, -1.4805584e-01,  1.9077774e+00,  1.1834401e+00,\n",
       "        3.1889176e-01, -2.3149686e-01, -1.3837130e+00,  2.1934405e-01,\n",
       "       -1.4903743e+00, -1.6660400e-01, -1.7060916e+00,  1.4057757e+00,\n",
       "       -7.7617514e-01, -3.6597294e-01,  8.0186379e-01,  1.0233827e+00,\n",
       "        1.6316348e+00,  6.6914642e-01,  1.4993818e+00,  4.6225034e-02,\n",
       "       -1.4042251e-02,  3.7955752e-01,  2.8582888e+00,  2.3708642e+00,\n",
       "        1.2090166e+00, -1.2345243e+00,  3.6924550e-01, -2.1291254e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_features('아 진짜 짜증난다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "653a221a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Int64Index: 1022 entries, 6 to 7875\n",
      "Series name: content\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "1022 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 16.0+ KB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9b0f9950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(comments):\n",
    "    dataset = []\n",
    "    \n",
    "    for s in comments:\n",
    "        dataset.append(get_features(s))\n",
    "        \n",
    "    commentFeatureVecs = np.stack(dataset)\n",
    "    return commentFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b9216c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1022"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(multi_class='multinomial', class_weight='balanced')\n",
    "\n",
    "X_train_vecs = get_dataset(X_train)\n",
    "lr.fit(X_train_vecs, y_train)\n",
    "\n",
    "X_test_vecs = get_dataset(X_test)\n",
    "\n",
    "preds = lr.predict(X_test_vecs)\n",
    "len(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3a5fb933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.6438356164383562 F1 Score : 0.6433425371989568\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "print(\"Accuracy : {}\".format(accuracy_score(preds, y_test)),\n",
    "    \"F1 Score : {}\".format(f1_score(preds, y_test, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ae518e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>여자들도 아무한테나 자기야라고하는사람있는데 그것도성희롱인것같은데요</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>대깨문이 문재인 협박범을 쉴드치네? 역시 대가리가 붕어인듯~</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>잘생겼다 근데 40대비율 너무높다 으</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>인직 너무 귀엽고 ❤️</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>고럼고럼 당연한거지</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7761</th>\n",
       "      <td>혜교보단 나이도 어리고 돌싱도 아니니까 미애가 승</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7788</th>\n",
       "      <td>홍상수♥김민희 알콩달콩 이쁜사랑하세요 ㅎㅎ 두분의 사랑을 응원합니다 ㅎㅎ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7835</th>\n",
       "      <td>환하나 지독한 인간 인 것 같네요. 박유천은 피해자이다. 이외에도 더 많은 피해자가...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7843</th>\n",
       "      <td>황민현 예능 나들이 늘 환영해요! 스윗한 황민현 너무 좋아요</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7875</th>\n",
       "      <td>희철이가 트와이스 사귀는거 보고 트와이스 하나 노리나 보다 ㅋㅋㅋㅋㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1022 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  label  preds\n",
       "6                  여자들도 아무한테나 자기야라고하는사람있는데 그것도성희롱인것같은데요      1      0\n",
       "13                    대깨문이 문재인 협박범을 쉴드치네? 역시 대가리가 붕어인듯~      0      0\n",
       "40                                 잘생겼다 근데 40대비율 너무높다 으      1      1\n",
       "55                                         인직 너무 귀엽고 ❤️      1      1\n",
       "60                                           고럼고럼 당연한거지      1      1\n",
       "...                                                 ...    ...    ...\n",
       "7761                        혜교보단 나이도 어리고 돌싱도 아니니까 미애가 승      0      1\n",
       "7788           홍상수♥김민희 알콩달콩 이쁜사랑하세요 ㅎㅎ 두분의 사랑을 응원합니다 ㅎㅎ      1      1\n",
       "7835  환하나 지독한 인간 인 것 같네요. 박유천은 피해자이다. 이외에도 더 많은 피해자가...      0      1\n",
       "7843                  황민현 예능 나들이 늘 환영해요! 스윗한 황민현 너무 좋아요      1      1\n",
       "7875            희철이가 트와이스 사귀는거 보고 트와이스 하나 노리나 보다 ㅋㅋㅋㅋㅋㅋ      1      0\n",
       "\n",
       "[1022 rows x 3 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['preds'] = preds\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7c879354",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>여자들도 아무한테나 자기야라고하는사람있는데 그것도성희롱인것같은데요</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1상으로 기사나오는건 첨봄 ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>스포츠 머리 난이도 존내 높다.옆머리 뜨는 것은 다운펌하는게 맞다.셀프 컷 하면 뒷...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>홍진영 귀에서 뭐 이어폰 같은거 빼던데 제작진이 뒤에서 조종하고있는거 아님?? 짜고...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>빠가야로~~ 안전하게 너희나 이빠이 쳐드세요!</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7661</th>\n",
       "      <td>해외여행 가니 좋냐</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7718</th>\n",
       "      <td>현무야... 버려</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7761</th>\n",
       "      <td>혜교보단 나이도 어리고 돌싱도 아니니까 미애가 승</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7835</th>\n",
       "      <td>환하나 지독한 인간 인 것 같네요. 박유천은 피해자이다. 이외에도 더 많은 피해자가...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7875</th>\n",
       "      <td>희철이가 트와이스 사귀는거 보고 트와이스 하나 노리나 보다 ㅋㅋㅋㅋㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  label  preds\n",
       "6                  여자들도 아무한테나 자기야라고하는사람있는데 그것도성희롱인것같은데요      1      0\n",
       "77                                    1상으로 기사나오는건 첨봄 ㅋㅋ      1      0\n",
       "147   스포츠 머리 난이도 존내 높다.옆머리 뜨는 것은 다운펌하는게 맞다.셀프 컷 하면 뒷...      0      1\n",
       "161   홍진영 귀에서 뭐 이어폰 같은거 빼던데 제작진이 뒤에서 조종하고있는거 아님?? 짜고...      1      0\n",
       "201                           빠가야로~~ 안전하게 너희나 이빠이 쳐드세요!      0      1\n",
       "...                                                 ...    ...    ...\n",
       "7661                                         해외여행 가니 좋냐      0      1\n",
       "7718                                          현무야... 버려      0      1\n",
       "7761                        혜교보단 나이도 어리고 돌싱도 아니니까 미애가 승      0      1\n",
       "7835  환하나 지독한 인간 인 것 같네요. 박유천은 피해자이다. 이외에도 더 많은 피해자가...      0      1\n",
       "7875            희철이가 트와이스 사귀는거 보고 트와이스 하나 노리나 보다 ㅋㅋㅋㅋㅋㅋ      1      0\n",
       "\n",
       "[364 rows x 3 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test['label'] != test['preds']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
